{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Логистическая регрессия. Метрики качества**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Подготовка для работы в Google Colab или Kaggle**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Код для подключения Google Drive в Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Код для получения пути к файлам в Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Код для установки библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy==1.26.4 pandas==2.1.4 scikit-learn==1.7.0 statsmodels==0.14.4 matplotlib==3.8.0 seaborn==0.13.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Важная информация**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для правильного воспроизведения результатов** решения задач:\n",
    "\n",
    "* Рекомендуется придерживаться имеющего в заданиях кода в исходной последовательности. Для этого при решении задач **восстановите недостающие фрагменты кода, которые отмечены символом** `...` (Ellipsis)\n",
    "\n",
    "* Если класс, функция или метод предусматривает параметр random_state, всегда указывайте **random_state=RANDOM_STATE**\n",
    "\n",
    "* Для всех параметров (кроме random_state) класса, функции или метода **используйте значения по умолчанию, если иное не указано в задании**\n",
    "\n",
    "**Если скорость обучения слишком низкая**, рекомендуется следующее:\n",
    "\n",
    "* В модели или/и GridSearchCV поменяйте значение параметра n_jobs, который отвечает за параллелизм вычислений\n",
    "\n",
    "* Воспользуйтесь вычислительными ресурсами Google Colab или Kaggle\n",
    "\n",
    "***Использовать GPU не рекомендуется, поскольку результаты обучения некоторых моделей могут отличаться на CPU и GPU.***\n",
    "\n",
    "После выполнения каждого задания **ответьте на вопросы в тесте.**\n",
    "\n",
    "**ВНИМАНИЕ:** **После каждого нового запуска ноутбука** перед тем, как приступить к выполнению заданий, проверьте настройку виртуального окружения, выполнив код в ячейке ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код для проверки настройки виртуального окружения\n",
    "\n",
    "import sys\n",
    "from importlib.metadata import version\n",
    "\n",
    "required = {\n",
    "    'python': '3.11.x',\n",
    "    'numpy': '1.26.4',\n",
    "    'pandas': '2.1.4',\n",
    "    'scikit-learn': '1.7.0',\n",
    "    'statsmodels': '0.14.4',\n",
    "    'matplotlib': '3.8.0',\n",
    "    'seaborn': '0.13.2'\n",
    "}\n",
    "\n",
    "print(f'{\"Компонент\":<15} | {\"Требуется\":<12} | {\"Установлено\":<12} | {\"Соответствие\"}')\n",
    "print('-' * 62)\n",
    "\n",
    "environment_ok = True\n",
    "for lib, req_ver in required.items():\n",
    "    try:\n",
    "        if lib == 'python':\n",
    "            inst_ver = sys.version.split()[0]\n",
    "            status = '✓' if sys.version_info.major == 3 and sys.version_info.minor == 11 else f'x (требуется {req_ver})'\n",
    "        else:\n",
    "            inst_ver = version(lib)\n",
    "            if inst_ver == req_ver:\n",
    "                status = '✓'\n",
    "            else:\n",
    "                environment_ok = False\n",
    "                status = f'x (требуется {req_ver})'\n",
    "    except:\n",
    "        environment_ok = False\n",
    "        inst_ver = '-'\n",
    "        status = 'x (не установлена)'\n",
    "    print(f'{lib:<15} | {req_ver:<12} | {inst_ver:<12} | {status}')\n",
    "\n",
    "print('\\nРезультат проверки: ', \n",
    "      '✓\\nВсе версии соответствуют требованиям' \n",
    "      if environment_ok else \n",
    "      'x\\nВНИМАНИЕ: Версии некоторых компонентов не соответствуют требованиям!\\n'\n",
    "      'Для решения проблемы обратитесь к инструкции по настройке виртуального окружения')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Импорт библиотек и вспомогательные функции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ece_score(y_true, y_score, n_bins=10):\n",
    "    \"\"\"\n",
    "    Возвращает значение метрики ECE для предсказанных вероятностей.\n",
    "    Для расчета ECE используется метод равномерного (uniform) распределения бинов (интервалы бинов имеют равную длину).\n",
    "\n",
    "    Аргументы:\n",
    "        y_true (numpy.ndarray): Истинные значения целевой переменной.\n",
    "        y_score (numpy.ndarray): Предсказанные вероятности целевого класса.\n",
    "        n_bins (int): Количество бинов. По умолчанию — 10.\n",
    "\n",
    "    Возвращает:\n",
    "        float: Значение метрики ECE для предсказанных вероятностей.\n",
    "    \"\"\"\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_indices = np.digitize(y_score, bins, right=True)\n",
    "    ece = 0.0\n",
    "    for i in range(1, n_bins + 1):\n",
    "        bin_mask = (bin_indices == i)\n",
    "        bin_size = bin_mask.sum()\n",
    "        if bin_size > 0:\n",
    "            bin_confidence = y_score[bin_mask].mean()\n",
    "            bin_accuracy = y_true[bin_mask].mean()\n",
    "            ece += (bin_size / len(y_true)) * abs(bin_accuracy - bin_confidence)\n",
    "    return ece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Практическая часть**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Градиентный спуск**\n",
    "\n",
    "Градиентный спуск (Gradient Descent) — это итерационный алгоритм численной оптимизации, используемый для нахождения локального минимума дифференцируемой функции. В контексте машинного обучения этой функцией является функция потерь (Loss Function), которая количественно оценивает ошибку модели.\n",
    "\n",
    "Алгоритм градиентного спуска основан на свойстве градиента многомерной функции. Пусть $J$ — дифференцируемая функция, $\\theta$ — вектор параметров функции. Тогда:\n",
    "\n",
    "* Градиент $\\nabla J(\\theta)$, — это вектор, который указывает направление наискорейшего возрастания функции. \n",
    "\n",
    "* Антиградиент $-\\nabla J(\\theta)$ — это вектор, который указывает направление наискорейшего убывания функции.\n",
    "\n",
    "**Алгоритм градиентного спуска (для функции потерь $J(\\theta)$):**\n",
    "\n",
    "1. Инициализация. Выбирается начальное приближение для вектора параметров $\\theta_0$ (например, случайным образом).\n",
    "\n",
    "2. Итерационное обновление. На каждом шаге алгоритма $t$ вектор параметров $\\theta_t$ обновляется по следующему правилу:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_{t} - \\alpha \\nabla J(\\theta_t)$$\n",
    "\n",
    "где $\\theta_t$ — значение параметров на шаге $t$, $\\alpha$ — параметр скорости обучения (learning rate), $\\nabla J(\\theta_t)$ — градиент функции потерь, вычисленный в точке $\\theta_t$.\n",
    "\n",
    "3. Критерий остановки. Итерационное обновление повторяется до тех пор, пока норма градиента не станет достаточно малой (что указывает на достижение точки, близкой к минимуму), либо пока не будет достигнуто заданное максимальное количество итераций.\n",
    "\n",
    "Скорость обучения $\\alpha$ является критически важным параметром:\n",
    "\n",
    "* Если $\\alpha$ слишком мала, алгоритм будет сходиться очень медленно. \n",
    "\n",
    "* Если $\\alpha$ слишком велика, алгоритм может начать расходиться, постоянно увеличивая ошибку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Задание 1***\n",
    "\n",
    "Пусть на отрезке $[-2; 2]$ задана функция $y(x)=x^4 + \\sin(x)$ (функция с одним параметром).\n",
    "\n",
    "Реализуйте простейший алгоритм градиентного спуска и найдите минимум функции `y_min`. Для нахождения минимума используйте параметры:\n",
    "\n",
    "* Начальное приближение (`x0`): 1.\n",
    "\n",
    "* Темп обучения (`learning_rate`): 0.1.\n",
    "\n",
    "* Количество итераций (`n_iter`): 1000.\n",
    "\n",
    "Рассчитайте оптимальный темп обучения — темп обучения, при котором алгоритм после первого же шага должен найти минимум функции `y_min`(начальное приближение `x0` — 1).\n",
    "\n",
    "Проверьте четыре значения темпа обучения на сходимость реализованного алгоритма (начальное приближение `x0` — 1, количество итераций `n_iter` — 1000): 0.4, 0.5, 0.6, 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополните функцию \n",
    "\n",
    "def func_y(x):\n",
    "    \"\"\"\n",
    "    Возвращает значение функции y в точке x.\n",
    "\n",
    "    Аргументы:\n",
    "        x (int|float): Значение параметра функции y.\n",
    "\n",
    "    Возвращает:\n",
    "        float: Значение функции y в точке x.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополните функцию gradient_y\n",
    "# Подсказка: используйте производную функции y(x)\n",
    "\n",
    "def gradient_y(x):\n",
    "    \"\"\"\n",
    "    Возвращает значение градиента функции y в точке x.\n",
    "\n",
    "    Аргументы:\n",
    "        x (int|float): Значение параметра функции y.\n",
    "\n",
    "    Возвращает:\n",
    "        float: Значение градиента функции y в точке x.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте график функции y на отрезке [-2; 2]\n",
    "\n",
    "x = np.linspace(-2, 2, num=10000)\n",
    "y = func_y(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задайте параметры для нахождения минимума\n",
    "\n",
    "x0 = 1\n",
    "learning_rate = 0.1\n",
    "n_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для удобства рекомендуется реализовать градиентный спуск с помощью функции (не обязательно)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдите минимум функции y\n",
    "\n",
    "x_min = ...\n",
    "y_min = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте график функции y на отрезке [-2; 2]\n",
    "# Дополните график точкой минимума\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.scatter(x=x_min, y=y_min, color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитайте оптимальный темп обучения\n",
    "# Начальное приближение (x0): 1\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверьте четыре значения темпа обучения на сходимость реализованного алгоритма\n",
    "# Начальное приближение (x0): 1\n",
    "# Количество итераций (n_iter): 1000.\n",
    "\n",
    "learning_rates = [0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Датасет *Diabetes prediction dataset***\n",
    "\n",
    "**Для решения заданий 2 — 9 рассмотрим датасет [Diabetes prediction dataset](https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset/data).**\n",
    "\n",
    "**ВНИМАНИЕ:** При решении заданий **используйте файл diabetes.csv** из приложения к ноутбуку, поскольку исходный датасет был изменен авторами курса.\n",
    "\n",
    "Набор данных предназначен для обучения и тестирования моделей бинарной классификации. Его основная цель — предсказать, есть ли у пациента диабет 2-го типа или нет. Набор данных включает в себя медицинские и демографические данные пациентов, а также информацию об их диабетическом статусе (положительный или отрицательный).\n",
    "\n",
    "Целевая переменная — diabetes (диабетический статус):\n",
    "\n",
    "* 1 — диагностирован диабет (**целевой класс**).\n",
    "\n",
    "* 0 — диабет не диагностирован.\n",
    "\n",
    "Датасет содержит признаки:\n",
    "\n",
    "* gender — пол.\n",
    "\n",
    "* age — возраст (в годах).\n",
    "\n",
    "* hypertension — наличие гипертонии.\n",
    "\n",
    "* heart_disease — наличие сердечно-сосудистых заболеваний.\n",
    "\n",
    "* bmi — индекс массы тела (BMI).\n",
    "\n",
    "* HbA1c_level — уровень гликированного гемоглобина.\n",
    "\n",
    "* blood_glucose_level — уровень глюкозы в крови."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Калибровочная кривая и ECE**\n",
    "\n",
    "**Калибровочная кривая (Calibration Curve)** — это инструмент для визуальной оценки того, насколько хорошо откалибрована модель. Она показывает соотношение между предсказанными вероятностями модели и фактической долей положительных исходов (реальным частотам положительных классов). На графике по оси X откладывается средняя предсказанная вероятность, а по оси Y — фактическая доля положительных классов.\n",
    "\n",
    "**ECE (Expected Calibration Error)** — это метрика, которая позволяет численно измерить ошибку калибровки.\n",
    "\n",
    "$$ECE=\\sum_{m=1}^{M}{\\frac{|B_m|}{n}{|acc(B_m) - conf(B_m)|}}$$\n",
    "\n",
    "где $M$ — количество бинов, $|B_m|$ — число предсказаний в бине $B_m$, $n$ — общее количество наблюдений, $acc(B_m)$ — доля истинных положительных результатов (эмпирическая вероятность) в бине $B_m$, $conf(B_m)$ — средняя предсказанная вероятность в бине $B_m$.\n",
    "\n",
    "При построении калибровочных кривых и расчёте ECE, все предсказания модели (например, из тестовой выборки) делятся на бины (группы) по уровню предсказанной вероятности. Как правило, используется метод равномерного (uniform) распределения бинов (интервалы бинов имеют равную длину). Например, в первый бин попадают все объекты с предсказанной вероятностью от 0 до 0.1, во второй — от 0.1 до 0.2, и так далее.\n",
    "\n",
    "Подробнее можно изучить по **ссылкам:**\n",
    "\n",
    "* [Калибровочные кривые | scikit-learn.ru](https://scikit-learn.ru/stable/modules/calibration.html#calibration-curve)\n",
    "\n",
    "* [Expected Calibration Error (ECE): A Step-by-Step Visual Explanation | towardsdatascience.com](https://towardsdatascience.com/expected-calibration-error-ece-a-step-by-step-visual-explanation-with-python-code-c3e9aa12937d/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Когда использовать AUC, а когда — ECE**\n",
    "\n",
    "**AUC (Area Under the ROC Curve)** — это метрика качества ранжирования. Она показывает, насколько хорошо модель способна отличать один класс от другого, присваивая объектам положительного класса более высокие оценки, чем объектам отрицательного. Высокий AUC означает, что модель хорошо разделяет классы.\n",
    "\n",
    "**Использовать AUC следует, когда в решаемой задаче важен порядок объектов, а не точные значения вероятностей.** \n",
    "\n",
    "**ECE (Expected Calibration Error)** — это метрика качества вероятностей. Она оценивает, соответствуют ли предсказанные моделью вероятности реальным частотам событий. Низкий ECE означает, что модель надежна, и её вероятностям можно доверять.\n",
    "\n",
    "**Использовать ECE следует, когда в решаемой задаче важны точные вероятности, а цена ошибки высока.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Задание 2***\n",
    "\n",
    "Выполните предобработку датасета (см. код задания) и обучите три модели логистической регрессии (LogisticRegression) на обучающей выборке:\n",
    "\n",
    "* `lr_diab` — логистическая регрессия **без регуляризации** на данных **без масштабирования** (`X_diab_train`).\n",
    "\n",
    "* `lr_diab_def` — логистическая регрессия **с регуляризацией по умолчанию** на данных **с масштабированием** (`X_diab_train_scaled`).\n",
    "\n",
    "* `lr_diab_opt` — логистическая регрессия **с оптимальным гиперпараметром регуляризации** на данных **с масштабированием** (`X_diab_train_scaled`). Оптимальный гиперпараметр регуляризации подберите с помощью GridSearchCV.\n",
    "\n",
    "Сравните качество калибровки моделей **на тестовой выборке**. Для этого постройте калибровочные кривые (функция [calibration_curve](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.calibration_curve.html)) и посчитайте метрику ECE (функция ece_score) для каждой из обученных моделей. На основе значения ECE выберите модель с наилучшей калибровкой. \n",
    "\n",
    "Сравните значение метрики AUC **на тестовой выборке** для обученных моделей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считайте набор данных\n",
    "\n",
    "df_diab = pd.read_csv('diabetes.csv')\n",
    "df_diab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используя метод info, определите типы признаков\n",
    "\n",
    "df_diab.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создайте списки количественных и категориальных переменных (не включая целевую переменную)\n",
    "\n",
    "diab_num_feat = ...\n",
    "diab_cat_feat = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделите объясняемый фактор в отдельную переменную\n",
    "\n",
    "X_diab, y_diab = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закодируйте категориальные признаки числами 0 и 1 с помощью OneHotEncoder\n",
    "\n",
    "diab_encoder = OneHotEncoder(sparse_output=False, drop='first').set_output(transform='pandas')\n",
    "\n",
    "X_diab_encoded = ...\n",
    "X_diab = X_diab.join(X_diab_encoded)\n",
    "X_diab = X_diab.drop(columns=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделите датасет на обучающую (60%) и тестовую (40%) выборки со стратификацией по целевой переменной\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "X_diab_train, X_diab_test, y_diab_train, y_diab_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабируйте количественные признаки\n",
    "#   train -> fit_transform\n",
    "#   test -> transform\n",
    "\n",
    "diab_scaler = StandardScaler().set_output(transform='pandas')\n",
    "\n",
    "X_diab_train_scaled = ...\n",
    "X_diab_test_scaled = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите модель lr_diab без регуляризации на данных без масштабирования\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "lr_diab = LogisticRegression(penalty=None, random_state=RANDOM_STATE).fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите модель lr_diab_def с регуляризацией по умолчанию на данных с масштабированием\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "lr_diab_def = LogisticRegression(random_state=RANDOM_STATE).fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите модель lr_diab_opt с оптимальным гиперпараметром регуляризации на данных с масштабированием\n",
    "# Оптимальные гиперпараметры обучения подберите с помощью GridSearchCV\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "params = {'C' : [0.1, 0.3, 0.5, 0.7, 1.0]}\n",
    "cv = 5\n",
    "\n",
    "cv_lr_diab_opt = ...\n",
    "lr_diab_opt = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите оптимальное значение гиперпараметра C\n",
    "\n",
    "C_opt = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполните предсказание вероятностей целевого класса на тестовой выборке моделью lr_diab\n",
    "# Учтите, что lr_diab обучалась на данных без масштабирования\n",
    "\n",
    "y_test_proba_lr_diab = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполните предсказание вероятностей целевого класса на тестовой выборке моделью lr_diab_def\n",
    "# Учтите, что lr_diab_def обучалась на данных с масштабированием\n",
    "\n",
    "y_test_proba_lr_diab_def = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполните предсказание вероятностей целевого класса на тестовой выборке моделью lr_diab_opt\n",
    "# Учтите, что lr_diab_opt обучалась на данных с масштабированием\n",
    "\n",
    "y_test_proba_lr_diab_opt = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Просчитайте калибровочные кривые моделей на тестовой выборке, используя calibration_curve (n_bins=10)\n",
    "\n",
    "prob_true_lr_diab, prob_pred_lr_diab = calibration_curve(..., n_bins=10)\n",
    "prob_true_lr_diab_def, prob_pred_lr_diab_def = calibration_curve(..., n_bins=10)\n",
    "prob_true_lr_diab_opt, prob_pred_lr_diab_opt = calibration_curve(..., n_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте калибровочные кривые\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Идеально калиброванная модель')\n",
    "plt.plot(prob_pred_lr_diab, prob_true_lr_diab, marker='o', label='lr_diab')\n",
    "plt.plot(prob_pred_lr_diab_def, prob_true_lr_diab_def, marker='o', label='lr_diab_def')\n",
    "plt.plot(prob_pred_lr_diab_opt, prob_true_lr_diab_opt, marker='o', label='lr_diab_opt')\n",
    "plt.xlabel('Средняя предсказанная вероятность модели')\n",
    "plt.ylabel('Частота положительных меток')\n",
    "plt.title('Калибровочные кривые (диаграмма надежности)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте метрику ECE для каждой из моделей, используя функцию ece_score\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте метрику AUC для каждой из моделей, используя функцию roc_auc_score\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Задание 3***\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Датасет **до масштабирования** из задания 2: `X_diab`, `y_diab`.\n",
    "\n",
    "* Оптимальное значение гиперпараметра регуляризации C из задания 2: `C_opt`. \n",
    "\n",
    "Проверьте, является ли разница в калибровочной точности моделей `lr_diab`, `lr_diab_def`, `lr_diab_opt` значимой (равны ли метрики ECE для данных моделей в среднем). Для проверки равенства средних значений в трех группах (векторы значений ECE для каждой из трех моделей) используйте t-тесты и F-тест для регрессии statsmodels (OLS) с фиктивными переменными для групп.\n",
    "\n",
    "**Посчитайте векторы значений ECE для 100 различных random_state.** Для каждой итерации $i=0,...,99$ (100 итераций):\n",
    "\n",
    "**ВНИМАНИЕ:** Где возможно, фиксируйте random_state для итерации $i$ на значении $i$.\n",
    "\n",
    "1. Разделите обучающую выборку `X_diab` на обучающую (60%, `X_diab_sample_train`) и валидационную (40%, `X_diab_sample_val`) **подвыборки** со стратификацией по целевой переменной. Не забудьте зафиксировать random_state=$i$.\n",
    "\n",
    "2. Обучите три модели логистической регрессии на обучающей подвыборке `X_diab_sample_train` (не забудьте масштабировать подвыборки `X_diab_sample_train` и `X_diab_sample_val` для моделей с регуляризацией, зафиксировать random_state=$i$):\n",
    "    \n",
    "    * `lr_diab_sample` — логистическая регрессия **без регуляризации** на данных **без масштабирования** (`X_diab_sample_train`).\n",
    "\n",
    "    * `lr_diab_sample_def` — логистическая регрессия **с регуляризацией по умолчанию** на данных **с масштабированием** (`X_diab_sample_train_scaled`).\n",
    "\n",
    "    * `lr_diab_sample_opt` — логистическая регрессия **с оптимальным гиперпараметром регуляризации** `C_opt` на данных **с масштабированием** (`X_diab_sample_train_scaled`). Используйте оптимальный гиперпараметр регуляризации `C_opt` из задания 2.\n",
    "\n",
    "3. Посчитайте метрику ECE (функция ece_score) для каждой из обученных моделей.\n",
    "\n",
    "Используя линейную регрессию statsmodels (OLS) и векторы значений ECE, **проверьте гипотезу о равенстве средних значений метрики ECE** в трех группах:\n",
    "\n",
    "1. Обучите модель линейной регрессии statsmodels (OLS) `ols_ece_diab` с факторными группами (с фиктивными переменными):\n",
    "\n",
    "    $$y = \\alpha+\\beta_{default}D_{default}+\\beta_{optimal}D_{optimal}​+ϵ$$\n",
    "\n",
    "    где $\\alpha=\\text{ECE}^{no\\_penalty}_{mean}$ — среднее значение ECE в группе с меткой $M^{no\\_penalty}$ (среднее ECE для модели `lr_diab`), $D_{m}$ — индикатор модели с меткой $M^{m}$.\n",
    "\n",
    "\n",
    "\n",
    "2. Интерпретируя summary модели `ols_ece_diab`, проверьте гипотезу о равенстве средних в трех группах с помощью t-теста для коэффициентов $\\beta_{default}$ и $\\beta_{optimal}$, а также F-теста для всей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте векторы значений ECE для 100 различных random_state\n",
    "# Для записи результатов итераций создадим датафрейм diab_ece_scores, заполненный нулями\n",
    "\n",
    "diab_ece_scores = pd.DataFrame({\n",
    "    'ece_no_penalty': np.zeros(100),\n",
    "    'ece_default': np.zeros(100),\n",
    "    'ece_optimal': np.zeros(100)\n",
    "}, index=range(100)\n",
    ")\n",
    "\n",
    "for i in range(100):\n",
    "    X_diab_i_train, X_diab_i_val, y_diab_i_train, y_diab_i_val = train_test_split(X_diab, y_diab, random_state=i, ...)\n",
    "    ...\n",
    "    diab_ece_scores.iloc[i] = np.array([\n",
    "        ece_score(...),\n",
    "        ece_score(...),\n",
    "        ece_score(...)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите средние значения ECE в каждой из трех групп\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Представим значения ECE в виде двух векторов: метка группы (group) и ECE наблюдения, соответствующего метке (ECE)\n",
    "\n",
    "diab_ece_groups = diab_ece_scores.melt()\n",
    "diab_ece_groups.columns = ['group', 'ECE']\n",
    "diab_ece_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сформируйте датафрейм для проверки гипотезы\n",
    "# Добавьте в датафрейм два столбца с фиктивными переменными:\n",
    "#   D_default = 1, если group = 'ece_default'; 0 — иначе\n",
    "#   D_optimal = 1, если group = 'ece_optimal'; 0 — иначе\n",
    "\n",
    "diab_ece_groups['D_default'] = ...\n",
    "diab_ece_groups['D_optimal'] = ...\n",
    "diab_ece_groups = diab_ece_groups.drop(columns=['group'])\n",
    "diab_ece_groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделите столбец ECE датафрейма diab_ece_groups в отдельную переменную\n",
    "\n",
    "X_diab_ece_groups, y_diab_ece_groups = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверьте гипотезу о равенстве средних значений метрики ECE в трех группах, используя ols_ece_diab\n",
    "# Выведите summary для ols_ece_diab\n",
    "# Перед обучением ols_ece_diab необходимо добавить константу к X_diab_ece_groups с помощью метода add_constant\n",
    "\n",
    "X_diab_ece_groups_const = ...\n",
    "ols_ece_diab = OLS(...).fit()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Задание 4***\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Тестовую выборку **до масштабирования** из задания 2: `X_diab_test`, `y_diab_test`.\n",
    "\n",
    "* Обученную модель `lr_diab` из задания 3.\n",
    "\n",
    "В рамках тестовой выборки `X_diab_test` отберите несколько пациентов по заданным условиям (метод [query](https://pandas.pydata.org/docs/user_guide/indexing.html#the-query-method)) и с помощью модели `lr_diab` предскажите вероятности целевого класса для каждого из этих пациентов. Условия для отбора пациентов:\n",
    "\n",
    "* Возраст — 54.\n",
    "\n",
    "* Пол — мужчина.\n",
    "\n",
    "* Наличие гипертонии — нет.\n",
    "\n",
    "* Наличие сердечно-сосудистых заболеваний — да.\n",
    "\n",
    "* Индекс массы тела (BMI) — от 27 (включительно) до 28 (включительно).\n",
    "\n",
    "* Уровень гликированного гемоглобина — не меньше 6.\n",
    "\n",
    "* Уровень глюкозы в крови — не больше 155."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В рамках тестовой выборки X_diab_test отберите несколько пациентов по заданным условиям\n",
    "\n",
    "X_diab_test_sample = X_diab_test.query(...)\n",
    "diab_test_sample_ids = X_diab_test_sample.index\n",
    "X_diab_test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C помощью модели lr_diab предскажите вероятности целевого класса для каждого из пациентов в X_diab_test_sample\n",
    "\n",
    "y_test_sample_lr_diab = pd.Series(..., index=diab_test_sample_ids)\n",
    "y_test_sample_lr_diab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Задание 5***\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Тестовую выборку **до масштабирования** из задания 2: `X_diab_test`, `y_diab_test`.\n",
    "\n",
    "* Датасет с отобранными в задании 4 пациентами: `X_diab_test_sample`.\n",
    "\n",
    "* Обученную модель `lr_diab` из задания 3.\n",
    "\n",
    "Для отобранных пациентов (`X_diab_test_sample`) скорректируйте данные при следующих **последовательных** событиях:\n",
    "\n",
    "1. Событие 1: коррекция оборудования. Выяснилось, что оборудование, собирающее анализы у пациентов, завышает значение уровня гликированного гемоглобина (HbA1c_level) у всех отобранных пациентов на 0.2. Уменьшите значение гликированного гемоглобина (HbA1c_level) у отобранных пациентов на 0.2.\n",
    "\n",
    "2. Событие 2: уточнение диагноза. Благодаря новым методам диагностики, у некоторых пациентов была диагностирована гипертония, в том числе и у всех отобранных пациентов. Для отобранных пациентов установите флаг наличия гипертонии (hypertension = 1).\n",
    "\n",
    "3. Событие 3: учет погрешности измерений. Чтобы учесть возможность ошибки в результатах анализов, было принято решение также считать вероятность диабета в случае, когда уровень глюкозы в крови (blood_glucose_level) выше текущего на величину стандартного отклонения в выборке (тестовой). Для отобранных пациентов увеличьте уровень глюкозы в крови (blood_glucose_level) на величину стандартного отклонения blood_glucose_level в тестовой выборке `X_diab_test_sample`.\n",
    "\n",
    "После каждой коррекции данных определите изменение вероятности предсказания наличия диабета для отобранных пациентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Событие 1: коррекция оборудования\n",
    "# Определите изменение вероятности предсказания наличия диабета при изменении HbA1c_level\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Событие 2: уточнение диагноза\n",
    "# Определите изменение вероятности предсказания наличия диабета при изменении hypertension\n",
    "# ВНИМАНИЕ: корректировка hypertension происходит после изменения HbA1c_level\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Событие 3: учет погрешности измерений\n",
    "# Определите изменение вероятности предсказания наличия диабета при изменении blood_glucose_level\n",
    "# ВНИМАНИЕ: корректировка blood_glucose_level происходит после изменения HbA1c_level и hypertension\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ColumnTransformer и Pipeline**\n",
    "\n",
    "ColumnTransformer и Pipeline из библиотеки scikit-learn — это инструменты, которые позволяют автоматизировать и упорядочить процесс предобработки данных для обучения моделей машинного обучения.\n",
    "\n",
    "**ColumnTransformer** — это инструмент, позволяющий применять различные преобразования к разным столбцам данных (например, числовым и категориальным), объединяя результаты в единую табличную структуру. Это особенно полезно для датасетов с разнородными типами признаков.\n",
    "\n",
    "В рамках заданий ColumnTransformer будет использоваться для автоматизации стандартных шагов предобработки (масштабирование числовых признаков и One-Hot кодирование категориальных признаков) перед подачей их в модель.\n",
    "\n",
    "**Pipeline (пайплайн, конвейер)** — это инструмент объединения последовательности этапов обработки данных и обучения модели в единый объект. Каждый этап пайплайна должен быть трансформатором (иметь методы fit и transform), кроме последнего, который может быть моделью (например, классификатором или регрессором). Это инкапсулирует всю цепочку действий, предотвращает утечку данных на обучающих/тестовых выборках, облегчает повторяемость экспериментов, делает код прозрачным и легко расширяемым. \n",
    "\n",
    "Pipeline интегрируется с инструментами автоматического подбора гиперпараметров (например, GridSearchCV или RandomizedSearchCV), с помощью чего возможно оптимизировать параметры как препроцессора, так и самой модели.\n",
    "\n",
    "В рамках заданий будет рассматриваться простейший пример пайплайна, где первым шагом выступает ColumnTransformer, а вторым — модель (например, LogisticRegression).\n",
    "\n",
    "*Поскольку пайплайн объединяет этапы обработки данных и сам алгоритм обучения в единый объект с методами fit и predict, его **упрощенно можно назвать моделью**. При этом важно помнить, что внутри пайплайна модель — это последний шаг, а предыдущие шаги отвечают за преобразование признаков.*\n",
    "\n",
    "* [Column Transformer with Mixed Types | scikit-learn.org](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html)\n",
    "\n",
    "* [Pipelines and composite estimators | scikit-learn.org](https://scikit-learn.org/stable/modules/compose.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Задание 6***\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Исходный датасет Diabetes prediction dataset из задания 2: `df_diab`.\n",
    "\n",
    "Выполните предобработку датасета `df_diab` и постройте пайплайн `pipe_clf`:\n",
    "\n",
    "1. Выделите объясняемый фактор в отдельную переменную `y_pipe`.\n",
    "\n",
    "2. Разделите датасет на обучающую (60%) и тестовую (40%) выборки со стратификацией по целевой переменной.\n",
    "\n",
    "3. Определите правило предобработки колонок с помощью `pipe_col_prep` (ColumnTransformer):\n",
    "\n",
    "    * Для категориальных переменных `diab_cat_feat` ('cat') — OneHotEncoder(drop='first', sparse_output=False).\n",
    "\n",
    "    * Для количественных переменных `diab_num_feat` ('num') — StandardScaler().\n",
    "\n",
    "4. Постройте пайплайн `pipe_clf` (Pipeline) из двух шагов:\n",
    "\n",
    "    1. 'col_prep': `pipe_col_prep`.\n",
    "\n",
    "    2. 'clf': LogisticRegression.\n",
    "\n",
    "Используя пайплайн `pipe_clf`, подберите оптимальный гиперпараметр регуляризации с помощью GridSearchCV **(метрика оптимизации — AUC)** и обучите модель с оптимальным параметром регуляризации `lr_pipe`.\n",
    "\n",
    "Используя регрессионные коэффициенты обученной модели `lr_pipe`, определите признак, который оказывает наибольшее влияние на прогноз диагноза (*подсказка: для извлечения коэффициентов используйте аттрибут named_steps*). Сравните коэффициенты модели `lr_pipe` (`pipe_coefs`) с коэффициентами модели `lr_diab` (`diab_coefs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделите объясняемый фактор в отдельную переменную\n",
    "\n",
    "X_pipe, y_pipe = df_diab.drop(columns=['diabetes']), df_diab['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделите датасет на обучающую (60%) и тестовую (40%) выборки со стратификацией по целевой переменной\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "X_pipe_train, X_pipe_test, y_pipe_train, y_pipe_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определите правило предобработки колонок с помощью pipe_col_prep (ColumnTransformer)\n",
    "\n",
    "pipe_col_prep = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', ..., diab_cat_feat),\n",
    "        ('num', ..., diab_num_feat),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте пайплайн pipe_clf\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "pipe_clf = Pipeline(\n",
    "    steps=[\n",
    "        ('col_prep', ...),\n",
    "        ('clf', LogisticRegression(random_state=RANDOM_STATE))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимальные гиперпараметры обучения подберите с помощью GridSearchCV\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "params = {'clf__C' : [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]}\n",
    "cv = 5\n",
    "scoring = 'roc_auc'\n",
    "\n",
    "cv_lr_pipe = GridSearchCV(\n",
    "    estimator=...,\n",
    "    param_grid=...,\n",
    "    cv=...,\n",
    "    scoring=...\n",
    ").fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите оптимальное значение гиперпараметра C\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучите модель lr_pipe с оптимальным гиперпараметром регуляризации\n",
    "\n",
    "lr_pipe = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используя коэффициенты lr_pipe, определите признак, который оказывает наибольшее влияние на прогноз диагноза\n",
    "\n",
    "pipe_coefs = pd.DataFrame({\n",
    "    'lr_pipe coef': ...\n",
    "}, index=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравните коэффициенты lr_pipe (pipe_coefs) с коэффициентами lr_diab (diab_coefs)\n",
    "\n",
    "diab_coefs = pd.DataFrame({\n",
    "    'lr_diab coef': ...\n",
    "}, index=...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Задание 7***\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Обученную модель `lr_pipe` из задания 6.\n",
    "\n",
    "* Тестовую выборку из задания 6: `X_pipe_test`, `y_pipe_test`.\n",
    "\n",
    "На тестовой выборке постройте матрицу ошибок для прогноза целевого класса моделью `lr_pipe` (функция [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)).\n",
    "\n",
    "На тестовой выборке интерпретируйте матрицу ошибок для модели `lr_pipe`, выбрав все верные утверждения из списка (см. тест):\n",
    "\n",
    "* Модель `lr_pipe` спрогнозировала у пациента из тестовой выборки наличие диабета. Вероятность ошибки этого прогноза больше 10%.\n",
    "\n",
    "* Врачи диагностировали у пациента из тестовой выборки диабет. Модель `lr_pipe` сможет сделать правильный прогноз для данного пациента с вероятностью, большей 80%.\n",
    "\n",
    "* Модель `lr_pipe` предоставила неверный прогноз для пациентов (в тестовой выборке), которые в реальности не имеют диагностированный диабет, больше, чем в 2% случаев.\n",
    "\n",
    "* Те пациенты (в тестовой выборке), у кого было предсказано отсутствие диабета (с помощью `lr_pipe`), в действительности имеют диабет менее, чем в 4% случаев.\n",
    "\n",
    "Постройте отчет по метрикам классификации (функция [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)) для модели `lr_pipe` на тестовой выборке и интерпретируйте результаты отчета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполните прогноз целевого класса на тестовой выборке с помощью модели lr_pipe\n",
    "\n",
    "y_test_pred_lr_pipe = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте матрицу ошибок для прогноза\n",
    "\n",
    "pipe_confusion_matrix = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте матрицу ошибок для удобства в интерпретации\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.heatmap(pipe_confusion_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "ax.set_title('Матрица ошибок')\n",
    "ax.set_xlabel('Предсказанный класс')\n",
    "ax.set_ylabel('Истинный класс')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель lr_pipe спрогнозировала у пациента из тестовой выборки наличие диабета. Вероятность ошибки этого прогноза больше 10%\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Врачи диагностировали у пациента из тестовой выборки диабет. Модель lr_pipe сможет сделать правильный прогноз для данного пациента с вероятностью, большей 80%\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель lr_pipe предоставила неверный прогноз для пациентов (в тестовой выборке), которые в реальности не имеют диагностированный диабет, больше, чем в 2% случаев\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Те пациенты (в тестовой выборке), у кого было предсказано отсутствие диабета (с помощью lr_pipe), в действительности имеют диабет менее, чем в 4% случаев.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте отчет по метрикам классификации\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Задание 8**\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Обученную модель `lr_pipe` из задания 6.\n",
    "\n",
    "* Тестовую выборку из задания 6: `X_pipe_test`, `y_pipe_test`.\n",
    "\n",
    "Постройте ROC-кривую для модели `lr_pipe` на тестовой выборке и рассчитайте метрику AUC (AUC-ROC).\n",
    "\n",
    "Для трех порогов классификации (0.25, 0.5, 0.75) для модели `lr_pipe` на тестовой выборке рассчитайте и сравните значения метрик: precision, recall, accuracy, f1.\n",
    "\n",
    "На отрезке [0, 1] найдите такое значение порога классификации, при котором метрика f1 будет принимать максимальное значение на тестовой выборке (шаг поиска `step` — 0.001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполните прогноз вероятностей целевого класса на тестовой выборке моделью lr_pipe\n",
    "\n",
    "y_test_proba_lr_pipe = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте ROC-кривую для модели lr_pipe на тестовой выборке и рассчитайте метрику AUC\n",
    "\n",
    "fpr_lr_pipe, tpr_lr_pipe, _ = roc_curve(...)\n",
    "auc_lr_pipe = roc_auc_score(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте ROC-кривую и значение AUC на графике\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(fpr_lr_pipe, tpr_lr_pipe, c='r', label=f'ROC-AUC: {auc_lr_pipe: .3f}')\n",
    "plt.title('ROC-кривая')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для трех порогов классификации для модели lr_pipe на тестовой выборке \n",
    "# рассчитайте и сравните значения метрик: precision, recall, accuracy, f1\n",
    "\n",
    "thresholds = [0.25, 0.5, 0.75]\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# На отрезке [0, 1] найдите такое значение порога классификации, при котором метрика f1 будет принимать максимальное значение на тестовой выборке\n",
    "# Шаг поиска — 0.001\n",
    "\n",
    "step = 0.001\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Коэффициент Джини**\n",
    "\n",
    "**Коэффициент Джини (Gini)** — это метрика оценки качества моделей бинарной классификации, которая представляет собой линейное преобразование метрики AUC (Area Under the ROC Curve):\n",
    "\n",
    "$$\\text{Gini}=2 \\times \\text{AUC}−1$$\n",
    "\n",
    "Значение Gini изменяется от 0 (отсутствие разделяющей способности) до 1 (идеальная модель), что позволяет интерпретировать Gini как меру корреляции между предсказанными вероятностями и истинными метками класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Задание 9***\n",
    "\n",
    "**ВНИМАНИЕ:** Для решения этого задания используйте:\n",
    "\n",
    "* Обученную модель `lr_pipe` из задания 6.\n",
    "\n",
    "* Тестовую выборку из задания 6: `X_pipe_test`, `y_pipe_test`.\n",
    "\n",
    "Реализуем две простые функции (модели) для предсказания вероятностей целевого класса в тестовой выборке:\n",
    "\n",
    "* `random_uniform` — функция (модель), предсказывающая вероятности случайно из равномерного распределения.\n",
    "\n",
    "* `linear_hba1c` — функция (модель), предсказывающая вероятности с помощью линейного преобразования (стандартизации) значений фактора HbA1c_level.\n",
    "\n",
    "На тестовой выборке сравните точность прогноза модели `lr_pipe` и функций (моделей) `random_uniform` и `linear_hba1c`, построив ROC-кривую и рассчитав значения метрики AUC и коэффициента Gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предскажите вероятности целевого класса в тестовой выборке с помощью random_uniform\n",
    "# Не забудьте зафиксировать RANDOM_STATE\n",
    "\n",
    "def random_uniform(N, random_state=None):\n",
    "    \"\"\"\n",
    "    Возвращает случайный прогноз вероятностей целевого класса из равномерного распределения.\n",
    "\n",
    "    Аргументы:\n",
    "        N (int): Длина вектора прогноза вероятностей целевого класса.\n",
    "        random_state (int): Параметр, фиксирующий случайное состояние результата выполнения функции. По умолчанию не используется (None).\n",
    "\n",
    "    Возвращает:\n",
    "        numpy.ndarray: Предсказанные вероятности целевого класса.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    return rng.uniform(0, 1, N)\n",
    "\n",
    "y_test_proba_random_uniform = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предскажите вероятности целевого класса в тестовой выборке с помощью linear_hba1c\n",
    "\n",
    "def linear_hba1c(hba1c_level):\n",
    "    \"\"\"\n",
    "    Возвращает прогноз вероятностей целевого класса с помощью линейного преобразования (стандартизации) значений фактора HbA1c_level.\n",
    "\n",
    "    Аргументы:\n",
    "        hba1c_level (numpy.ndarray): Вектор значений фактора HbA1c_level в тестовой выборке.\n",
    "        \n",
    "    Возвращает:\n",
    "        numpy.ndarray: Предсказанные вероятности целевого класса.\n",
    "    \"\"\"\n",
    "    return (hba1c_level - hba1c_level.min()) / (hba1c_level.max() - hba1c_level.min())\n",
    "\n",
    "y_test_proba_linear_hba1c = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополните функцию gini\n",
    "\n",
    "def gini(y_true, y_score):\n",
    "    \"\"\"\n",
    "    Возвращает значение коэффициента Gini для предсказанных вероятностей.\n",
    "\n",
    "    Аргументы:\n",
    "        y_true (numpy.ndarray): Истинные значения целевой переменной.\n",
    "        y_score (numpy.ndarray): Предсказанные вероятности целевого класса.\n",
    "\n",
    "    Возвращает:\n",
    "        float: Значение коэффициента Gini для предсказанных вероятностей.\n",
    "    \"\"\"\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Постройте ROC-кривые для random_uniform и linear_hba1c на тестовой выборке\n",
    "\n",
    "fpr_random_uniform, tpr_random_uniform, _ = ...\n",
    "fpr_linear_hba1c, tpr_linear_hba1c, _ = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитайте метрику AUC для random_uniform и linear_hba1c на тестовой выборке\n",
    "\n",
    "auc_random_uniform = ...\n",
    "auc_linear_hba1c = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитайте коэффициент Gini для lr_pipe, random_uniform и linear_hba1c на тестовой выборке\n",
    "\n",
    "gini_lr_pipe = ...\n",
    "gini_random_uniform = ...\n",
    "gini_linear_hba1c = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте ROC-кривые и сравните значения AUC и Gini для трех моделей\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(..., ..., c='g', label=...)\n",
    "plt.plot(..., ..., c='r', label=...)\n",
    "plt.plot(..., ..., c='m', label=...)\n",
    "plt.title('ROC-кривые')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
